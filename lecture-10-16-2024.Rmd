---
output:
  word_document: default
  pdf_document: default
  html_document:
    theme: readable
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "10-16-2024"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
output:
  html_document: 
    theme: readable
  pdf_document: default
urlcolor: blue
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
  - \usepackage{array}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = "", message = FALSE, out.width = "100%", fig.align = "center", cache = FALSE, dev = ifelse(knitr::is_html_output(), "png", "pdf"))
```

```{r packages, echo = FALSE}
library(tidyverse)
suppressWarnings(library(kableExtra))
```

```{r utilities, echo = FALSE}
source("../../utilities.R")
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`

<!-- Note: Need \usepackage{array} to create PDF for this for some reason.  -->

```{r}
rss <- function(y.pop, k, m = 1, x, x.pop = y.pop) {
  
  N <- length(y.pop)
  y.smp <- matrix(NA, k, m)
  
  for (i in 1:m) {
    for (j in 1:k) {
      index <- sample(1:N, k)
      y.tmp <- y.pop[index]
      x.tmp <- x.pop[index]
      y.tmp <- y.tmp[order(x.tmp)]
      y.smp[j,i] <- y.tmp[j]
    }
  }  
  
  return(mean(y.smp))
}
```

## Ordered Systematic Sampling with Periodic Target Variables

Ordered systematic sampling with periodic target variables requires careful specification of the sampling units. 

**Example**: This is a poorly designed 1-in-360 ordered systematic sampling design. The within-cluster variability is very low. 
```{r, fig.width = 9}
set.seed(101)

x <- 1:1440
y <- sin(x/1440 * 8*pi) + 10 + rnorm(length(x), 0, 0.125)

d <- data.frame(y,x)
p <- ggplot(d, aes(x = x, y = y)) + theme_minimal()
p <- p + geom_point(alpha = 0.5, size = 1)
p <- p + labs(x = "Minute", y = "Target Variable")
p <- p + geom_vline(xintercept = seq(0, 1440, by = 1440/4))
p <- p + scale_x_continuous(breaks = seq(0, 1440, by = 60))
plot(p)
```
Consider the results of a simulation study with three designs: simple random sampling, stratified random sampling (using the 360 minute intervals as strata), and the 1-in-360 systematic sampling design. 
```{r, fig.width = 9}
rep <- 1000

e.srs <- rep(NA, rep) 
e.str <- rep(NA, rep) 
e.sys <- rep(NA, rep) 

for (i in 1:rep) {
  e.srs[i] <- mean(y[sample(1:1440, 4)])
  e.sys[i] <- mean(y[seq(sample(1:360, 1), length = 4, by = 360)])
  
  z <- rep(NA, 4)
  for (j in 1:4) {
    z[j] <- y[sample(seq((j - 1) * 360 + 1, j * 360), 1)]  
  }
  e.str[i] <- mean(z)
}

d <- data.frame(estimate = c(e.srs, e.str, e.sys), 
  design = rep(c("Simple","Stratified","Systematic"), each = rep))

p <- ggplot(d, aes(x = estimate))
p <- p + geom_density(adjust = 2) + facet_wrap(~ design)
p <- p + xlab("Estimate")
p <- p + theme_minimal() + noyaxis
p

d %>% rename(Design = design) %>% group_by(Design) %>% summarize(Variance = var(estimate), Bound = 2*sqrt(Variance)) %>% ktbl()
```

**Example**: This is a well designed 1-in-180 ordered systematic sampling design. The within-cluster variability is much higher. 
```{r, fig.width = 9}
x <- 1:1440
y <- sin(x/1440 * 8*pi) + 10 + rnorm(length(x), 0, 0.125)

d <- data.frame(y,x)
p <- ggplot(d, aes(x = x, y = y)) + theme_minimal()
p <- p + geom_point(alpha = 0.5, size = 1)
p <- p + labs(x = "Minute", y = "Target Variable")
p <- p + geom_vline(xintercept = seq(0, 1440, by = 1440/8))
p <- p + scale_x_continuous(breaks = seq(0, 1440, by = 60))
plot(p)
```
Consider the results of a simulation study with three designs: simple random sampling, stratified random sampling (using the 180 minute intervals as strata), and the 1-in-180 systematic sampling design. 
```{r, fig.width = 9}
rep <- 1000

e.srs <- rep(NA, rep) 
e.str <- rep(NA, rep) 
e.sys <- rep(NA, rep) 

for (i in 1:rep) {
  e.srs[i] <- mean(y[sample(1:1440, 8)])
  e.sys[i] <- mean(y[seq(sample(1:180, 1), length = 8, by = 180)])
  
  z <- rep(NA, 8)
  for (j in 1:8) {
    z[j] <- y[sample(seq((j - 1) * 180 + 1, j * 180), 1)]  
  }
  e.str[i] <- mean(z)
}

d <- data.frame(estimate = c(e.srs, e.str, e.sys), 
  design = rep(c("Simple","Stratified","Systematic"), each = rep))

p <- ggplot(d, aes(x = estimate))
p <- p + geom_density(adjust = 2) + facet_wrap(~ design)
p <- p + xlab("Estimate") 
p <- p + theme_minimal() + noyaxis
p

d %>% rename(Design = design) %>% group_by(Design) %>% summarize(Variance = var(estimate), Bound = 2*sqrt(Variance)) %>% ktbl()
```

## Systematic Sampling as Cluster Sampling

Recall that in cluster sampling we have $M$ elements in $N$ clusters. The number of clusters sampled is $n$, and the number of elements in the $i$-th cluster is $m_i$. 

**Example**: Researchers are interested in estimating the number of otter dens along a coastline. They divided the coastline into 50 ordered sections and used a 1-in-10 ordered systematic sampling design where they randomly selected one of the first 10 sections, and then selected every 10th section after that section. In their survey they selected the 7th, 17th, 27th, 37th, and 47th sections. For this design what is the number of elements in the population ($M$), the number of clusters in the population ($N$), the number of clusters sampled ($n$), and the number of elements per cluster ($m_i$, which is the same for each cluster in this design)? 

What if they then selected one of the remaining 9 initial sections, selecting the 2nd, so that they then also selected the 12th, 22nd, 32nd, and 42nd sections. What changes?

\pagebreak

## Variance Estimation in Systematic Sampling

In cluster sampling, the variance of an estimator cannot be estimated based on one sampled cluster (see the formulas for the estimated variance of the estimators to see why). So a single 1-in-*k* set of elements or a single grid of elements is not sufficient to estimate the variance of an estimator. There are several solutions. 

1. Treat the elements in a cluster as a simple random sample.

0. Use *repeated* systematic sampling.  

0. Model-based approaches.

**Repeated** systematic sampling simply involves selecting *multiple* 1-in-$k$ samples, each of which is a cluster. This is also a good way to simply increase the number of elements sampled. 

## Motivation for Ranked Set Sampling

Suppose that we could first *sort* the elements in increasing order with respect to the value of the target variable prior to applying systematic or stratified sampling. 

```{r, fig.height = 3}
set.seed(101)
x <- 1:1000
y <- 10 + rnorm(length(x), 0, 1)
y <- y - mean(y) + 10

d <- data.frame(x = x, y = y)
p <- ggplot(d, aes(x = x, y = y)) + theme_minimal()
p <- p + geom_vline(xintercept = seq(0, 1000, by = 100) + 0.5, linetype = 2)
p <- p + geom_point(alpha = 0.5, size = 1)
p <- p + geom_point(aes(y = sort(y)), alpha = 0.5, size = 1)
p <- p + labs(x = "Element Index", y = "Target Variable")
plot(p)

y <- sort(y)
tmp <- data.frame(y = y, g = factor(rep(1:10, 100)))
```

```{r, fig.height = 3, fig.width = 9}
samp <- function(y) {
  y.sys <- y[seq(sample(1:100, 1), length = 10, by = 100)]
  y.srs <- y[sample(1:1000, 10)]
  y.str <- rep(NA,4)
  for (i in 1:10) {
    y.str[i] <- y[sample(seq((i-1)*100 + 1, i*100), 1)]
  }
  return(c(mean(y.sys), mean(y.srs), mean(y.str)))
}

rep <- 1000
tmp <- t(replicate(rep, samp(y)))
tmp <- data.frame(y = as.vector(tmp),
  method = rep(c("Systematic","Simple","Stratified"), each = rep))
tmp$method <- ordered(tmp$method, levels = c("Simple","Systematic","Stratified"))

evar <- as.data.frame(round(aggregate(y ~ method, data = tmp, var)$y, 4))
names(evar) <- "text"
evar$x <- 9.25
evar$y <- 1.4
evar$method = c("Simple","Systematic","Stratified")

p <- ggplot(tmp, aes(x = y))
p <- p + geom_density(adjust = 3) + facet_wrap(~ method)
p <- p + xlab("Estimate") 
p <- p + theme_minimal() + noyaxis
plot(p)

tmp %>% rename(Design = method) %>% group_by(Design) %>% summarize(Variance = var(y), Bound = 2*sqrt(Variance)) %>% ktbl()
```

## Ranked Set Sampling

A basic ranked set sampling design (with one cycle) can be described as follows.

1. *Select* $k$ sets of $k$ elements using simple random sampling. 

0. *Sort* the elements *within each set* with respect to the target variable using an auxiliary variable that is thought to be correlated with the target variable. 

0. In the *first set*, observe the target variable for the element *ranked first*. In the *second set*, observe the target variable for the element *ranked second*. And so on until you have observed the target variable for $k$ elements. 

Let $y_{(i)j}$ denote the value of the target variable for the element ranked $i$-th in the $j$-th set. That is, we assume that 
$$
  y_{(1)j} \ge y_{(2)j} \ge \cdots \ge y_{(k)j},
$$
or 
$$
  y_{(1)j} \le y_{(2)j} \le \cdots \le y_{(k)j},
$$
for all $k$ sets (direction of ranking doesn't matter provided it is the same for all sets). 

```{r}
r1 <- c("$\\boxed{y_{(1)1}}$","$y_{(1)2}$","$y_{(1)3}$", "$\\cdots$", "$y_{(1)k}$")
r2 <- c("$y_{(2)1}$","$\\boxed{y_{(2)2}}$","$y_{(2)3}$", "$\\cdots$", "$y_{(2)k}$")
r3 <- c("$y_{(3)1}$","$y_{(3)2}$","$\\boxed{y_{(3)3}}$", "$\\cdots$", "$y_{(3)k}$")
r4 <- c("$\\vdots$","$\\vdots$","$\\vdots$","$\\ddots$","$\\vdots$")
r5 <- c("$y_{(k)1}$","$y_{(k)2}$","$y_{(k)3}$", "$\\cdots$", "$\\boxed{y_{(k)k}}$")
c0 <- c(1, 2, 3, "$\\vdots$", "***k***", "")
r6 <- c("$\\boxed{y_{(1)1}}$","$\\boxed{y_{(2)2}}$","$\\boxed{y_{(3)3}}$", "$\\cdots$", "$\\boxed{y_{(k)k}}$")
d <- data.frame(cbind(c0,rbind(r1,r2,r3,r4,r5,r6)))
rownames(d) <- NULL
names(d) <- c("Rank", 1, 2, 3, "$\\cdots$", "$k$")
ktbl(d) %>% column_spec(1, bold = FALSE) %>% add_header_above(c(" " = 1, "Set" = 5))
```

**Example**: Consider a ranked set sampling design with $k$ = 3. Suppose the first set of observations of the target variable would be 1.2, 0.9, and 1.3, the second set would be 0.8, 1.1, and 0.2, and the third set would be 1.9, 0.1, and 1.4. Assuming *perfect* ranking with respect to the target variable, what would be our sample of observations?

\vspace{3cm}

Examples of applications of ranked set sampling. 
```{r}
element <- c("quadrat","tree","gasoline sample","household","newborn baby")
target <- c("forage","dry bark weight","laboratory RVP","income (long form)","bilirubin level")
ranking <- c("visual inspection","estimated volume","field RVP","income (short form)","visual inspection")
d <- data.frame(Element = element, target = target, ranking = ranking)
names(d)[2:3] <- c("Target Variable","Ranking Method")
ktbl(d)
```

## Comparison of RSS and SRS

1. SRS requires selection and observation of $n$ elements, while RSS requires selection and *ranking* of $n^2$ elements, and then the observation of $n$ elements.

2. The sample mean $\bar{y}$ is an unbiased estimator of $\mu$ for both designs.

3. The design effect of RSS has the property that
$$
  \frac{2}{k+1} \le \frac{V_{\small \text{RSS}}(\bar{y})}{V_{\small \text{SRS}}(\bar{y})} \le 1,
$$
and tends to be closer to $2/(k+1)$, particularly in cases where the population distribution is nearly symmetric. 

Given that RSS is more expensive, when would it be preferred to SRS? Why would it be preferred to stratified or systematic sampling?

## Simulation Study

```{r, fig.height = 4, fig.width = 9}
N <- 1000
y.pop <- rnorm(N, 100, 5)
y.pop <- y.pop - mean(y.pop) + 100
r <- 10000
n <- c(2,3,5)

y.srs <- rep(NA, r) 
y.rss <- rep(NA, r)
  
tmp <- vector("list", length = 3)

for (j in 1:3) {
  for (i in 1:r) {
    y.srs[i] <- mean(sample(y.pop, n[j]))
    y.rss[i] <- rss(y.pop, n[j])
  }
  tmp[[j]] <- data.frame(y = c(y.srs, y.rss), 
  	design = rep(c("SRS", "RSS"), each = r), n = n[j])
}

tmp <- do.call("rbind", tmp)  

tmp$n <- factor(tmp$n)
levels(tmp$n) <- paste("k = " , levels(tmp$n))

deff <- with(tmp, tapply(y, list(design, n), var))
deff <- round(deff[1,]/deff[2,],2)
deff <- data.frame(x = rep(95,3), y = rep(0.25, 3), n = levels(tmp$n), deff = deff)

p <- ggplot(tmp, aes(x = y)) + facet_wrap(~n)
p <- p + geom_density(aes(fill = design), colour = NA, adjust = 3, alpha = 0.5)
p <- p + geom_density(aes(fill = design), colour = "black", show.legend = FALSE, adjust = 3, alpha = 0.5)
p <- p + scale_fill_discrete(guide = guide_legend(title = "Design"))
p <- p + scale_colour_discrete(guide = guide_legend(title = "Design"))
p <- p + xlab("Estimate") 
p <- p + geom_text(aes(x = x, y = y, label = deff), data = deff)
p <- p + geom_point(aes(x = x, y = y), data = data.frame(x = 100, y = -0.01), size = 2, pch = 17)
p <- p + theme_minimal() + noyaxis
p
```

Note: The number shown in each graph is the *design effect* of the ranked set sampling design. 

## Multiple Cycles

To increase the sample size, we could increase the number of sets $k$, or increase the number of *cycles* ($m$). The total sample size is then $n$ = $km$. 

**Example**: Consider a ranked set sampling design with $k$ = 3 sets and $m$ = 2 cycles. Suppose that for the first cycle the first set of observations of the target variable would be 1.2, 0.9, and 1.3, the second set would be 0.8, 1.1, and 0.2, and the third set would be 1.9, 0.1, and 1.4. And for the second cycle the first set of observations of the target variable would be 1.0, 1.2, and 1.8, the second set would be 1.7, 0.7, and 1.0, and the third set would be 2.0, 1.1, and 1.2. Assuming *perfect* ranking with respect to the target variable, what would be our sample of observations?

\vspace{3cm}

## Simulation Study of Multiple Cycles

Consider the design effects of three combinations of $k$ and $m$ that all yield a sample size of $km$ = 30. 

```{r, fig.height = 4, fig.width = 9}
N <- 1000
y.pop <- rnorm(N, 100, 5)
y.pop <- y.pop - mean(y.pop) + 100
r <- 1000

k <- c(2,3,5)
m <- c(15,10,6)

y.srs <- rep(NA, r) 
y.rss <- rep(NA, r)

tmp <- vector("list", length = 3)

for (j in 1:3) {
  for (i in 1:r) {
    y.srs[i] <- mean(sample(y.pop, k[j] * m[j]))
    y.rss[i] <- rss(y.pop, k = k[j], m = m[j])
  }
  tmp[[j]] <- data.frame(y = c(y.srs, y.rss), 
    design = rep(c("SRS", "RSS"), each = r), k = k[j], m = m[j])
}


tmp <- do.call("rbind", tmp)  

tmp$k <- factor(tmp$k)
tmp$m <- factor(tmp$m)

tmp$g <- NA
for (i in 1:nrow(tmp)) {
  tmp$g[i] <- paste("k = ", tmp$k[i], ", ", "m = ", tmp$m[i], sep = "")
}
tmp$g <- factor(tmp$g)

deff <- with(tmp, tapply(y, list(design, g), var))
deff <- round(deff[1,]/deff[2,],2)
deff <- data.frame(x = rep(98,3), y = rep(0.5, 3), g = levels(tmp$g), deff = deff)

p <- ggplot(tmp, aes(x = y)) + facet_wrap(~ g)
p <- p + geom_density(aes(fill = design), colour = NA, adjust = 3, alpha = 0.5)
p <- p + geom_density(aes(fill = design), colour = "black", show.legend = FALSE, adjust = 3, alpha = 0.5)
p <- p + scale_fill_discrete(guide = guide_legend(title = "Design"))
p <- p + scale_colour_discrete(guide = guide_legend(title = "Design"))
p <- p + xlab("Estimate")
p <- p + theme_minimal() + noyaxis
p <- p + geom_text(aes(x = x, y = y, label = deff), data = deff)
p <- p + geom_point(aes(x = x, y = y), data = data.frame(x = 100, y = -0.02), size = 2, pch = 17)
p
```
For perfect rankings it would be best to have a larger set size ($k$) rather than a larger number of cycles ($m$). But this may not be a good idea in practice. Why? 

## Imperfect Rankings

Suppose that ranking is based on an auxiliary variable that is correlated with the target variable. 

```{r, fig.height = 4, fig.width = 9}

N <- 1000
r <- 1000

y.srs <- rep(NA, r) 
y.rss <- rep(NA, r)

tmp <- vector("list", length = 4)

rho <- c(0.5,0.7,0.9, 1.0)

for (j in 1:4) {
  ugh <- MASS::mvrnorm(N, c(100,100), matrix(sqrt(5) * c(1, rho[j], rho[j], 1), 2, 2))
  y.pop <- ugh[,1]; y.pop <- y.pop - mean(y.pop) + 100
  x.pop <- ugh[,2]; x.pop <- x.pop - mean(x.pop) + 100
  for (i in 1:r) {
    y.srs[i] <- mean(sample(y.pop, 50))
    y.rss[i] <- rss(y.pop, k = 5, m = 10, x.pop = x.pop)
  }
  tmp[[j]] <- data.frame(y = c(y.srs, y.rss), 
    design = rep(c("SRS", "RSS"), each = r), rho = rho[j])
}


tmp <- do.call("rbind", tmp)  

tmp$rho <- factor(tmp$rho)
levels(tmp$rho) <- paste("Correlation:", rho)

deff <- with(tmp, tapply(y, list(design, rho), var))
deff <- round(deff[1,]/deff[2,],2)
deff <- data.frame(x = rep(99.5,4), y = rep(2.1, 4), rho = levels(tmp$rho), deff = deff)

p <- ggplot(tmp, aes(x = y)) + facet_wrap(~ rho, ncol = 4)
p <- p + geom_density(aes(fill = design), colour = NA, adjust = 3, alpha = 0.5)
p <- p + geom_density(aes(fill = design), colour = "black", show.legend = FALSE, adjust = 3, alpha = 0.5)
p <- p + scale_fill_discrete(guide = guide_legend(title = "Design"))
p <- p + scale_colour_discrete(guide = guide_legend(title = "Design"))
p <- p + xlab("Estimate")
p <- p + theme_minimal() + noyaxis
p <- p + geom_text(aes(x = x, y = y, label = deff), data = deff)
p <- p + geom_point(aes(x = x, y = y), data = data.frame(x = 100, y = -0.1), size = 2, pch = 17)
p
```

